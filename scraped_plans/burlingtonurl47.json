{
    "FILE_NAME": "https://repository.library.noaa.gov/view/noaa/31252/noaa_31252_DS1.pdf",
    "ALL TEXT": "Climate Assessments for Local Action chriStine J. Kirchhoff, JoSeph J. BarSugli, gillian l. galford, amBariSh V. KarmalKar, Kelly lomBardo, Scott r. StephenSon, matheW BarloW, anJi Seth, guiling Wang, and auStin franK W hile climate change is a global phenomenon, the associated impacts such as heat waves, droughts, wildfires, and storms are dev- astating to local communities [U.S. Global Change Research Program (USGCRP) 2017]. The frequency and severity of these events have renewed interest in better understanding local impacts and adaptation options (Bierbaum et al. 2013). As states and communities’ interest in climate change impacts and ad- aptation grows, so does their need Fig. 1. Scale, purpose, and audience of global, national, and state CAs. for usable climate information. Global and national climate assessments (CAs) under the auspices of the Intergovernmental Panel are comprehensive, authoritative sources of informa- on Climate Change (IPCC) and USGCRP involving tion about observed and projected climate changes synthesis and evaluation of scientific studies by hun- and their impacts on society, like those undertaken dreds (or thousands) of recognized experts (IPCC 2014; USGCRP 2017). Assessments aim to produce credible, legitimate, policy-relevant, scientific information to AFFILIATIONS: Kirchhoff, StephenSon, Seth, Wang, and inform policy and decisions (Farrell and Jäger 2006; franK—University of Connecticut, Storrs, Connecticut; Jacobs and Buizer 2016; Mach and Field 2017; Mitchell BarSugli—Cooperative Institute for Research in Environmental et al. 2006). Unfortunately, there remains a disconnect Sciences, University of Colorado Boulder, and NOAA/ESRL/ between the information in these global and national PSD, Boulder, Colorado; galford—University of Vermont, CAs and what states and communities need to inform Burlington, Vermont; KarmalKar—Northeast Climate Adaptation Science Center, and University of Massachusetts local decision-making (see Fig. 1). Amherst, Amherst, Massachusetts; lomBardo—University of To address this disconnect, more and more states Connecticut, Groton, Connecticut; BarloW—University of are undertaking CAs (see Table 1, and for more in- Massachusetts Lowell, Lowell, Massachusetts formation, see supplemental Table ES1) but with little CORRESPONDING AUTHOR: Christine J. Kirchhoff, guidance for how to organize and conduct compre- christine.kirchhoff@uconn.edu hensive, authoritative, and usable assessments at this The abstract for this article can be found in this issue, following the scale. While 40 years of research on global and na- table of contents. tional assessments provides a starting point to guide DOI:10.1175/BAMS-D-18-0138.1 state climate assessment (SCA) efforts to produce A supplement to this article is available online (10.1175/BAMS-D-18-0138.2) credible, legitimate, and policy-relevant information, there are unique aspects of state assessments that ©2019 American Meteorological Society fall outside the range of techniques used to develop For information regarding reuse of this content and general copyright information, consult the AMS Copyright Policy. assessments at larger scales. To address the need for comprehensive SCA guidance, the authors convened AMERICAN METEOROLOGICAL SOCIETY NOVEMBER 2019 | 2147 Brought to you by NOAA Central Library | Unauthenticated | Downloaded 07/13/21 12:17 PM UTCTable 1. States with SCAs with most recent SCA year. controversial findings are excluded, and Interviewees included representatives from all SCAs listed when political forces try to delegitimize or except Maryland and Delaware. discredit the assessment (Morgan et al. 2005; Vardy et al. 2017). Second, being transparent, State Year State Year ensuring fair participation, and engaging published published with policy- and decision-makers and the Delaware 2014 Nebraska 2014 general public enhances legitimacy resulting in buy-in and support for CAs (Farrell and California 2018 New Mexico 2005 Jäger 2006; Mitchell et al. 2006; Mach and Colorado 2014 New York 2011 Field 2017; Vardy et al. 2017). For example, consistent engagement with national govern- Connecticut — Oregon 2019 ment representatives during the IPCC AR4 Pacific Islands 2012 Pennsylvania 2015 enhanced legitimacy and created support Indiana 2018 Rhode Island1 2017 for the assessment (Vardy et al. 2017), while opportunities for both public and stakeholder Maryland 2018 Vermont 2014 input enhanced legitimacy of the third U.S. Massachusetts 2018 Washington 2013 NCA (Cloyd et al. 2016). Finally, salience is about the relevance of assessment informa- Montana 2017 Wisconsin 2011 tion for decision-making or the public (Cash 1 The Rhode Island state climate summary is one of 50 state summaries pro- et al. 2003). Scholars of global and national duced by NCICS. assessments suggest that achieving salience requires engaging with policy- and decision- a workshop (November 2017) at which participants makers in the production of assessment information discussed lessons learned beyond review of the litera- and using effective and varied communication strate- ture on global and national CAs, as well as from their gies (Buizer et al. 2016; Farrell and Jäger 2006; Mach experiences conducting four SCAs—Connecticut, and Field 2017; Mitchell et al. 2006; Pearce et al. 2018). Vermont, Massachusetts, and Colorado. In 2018, the authors conducted interviews to learn from the LEARNING FROM STATE CLIMATE AS- experiences of 10 additional U.S. SCAs. Drawing on SESSMENTS: WORKSHOP AND INTER- the literature and firsthand experience of the authors VIEWS. The authors convened “Methodologies and and interview participants, we sought to understand Engagement for State Level Climate Assessment” on 1) how global and national CAs produce credible, 6 November 2017 at the University of Connecticut, legitimate, and salient scientific information to help Storrs campus. Approximately 25 individuals includ- guide SCAs; 2) similarities and differences between ing the authors and other faculty, staff, and students assessments at state and other scales; 3) unique chal- from the University of Connecticut participated in lenges faced by SCAs; and 4) lessons learned from the event. The open portion of the event included five existing SCAs that may help guide future assessments. presentations and a panel discussion designed to share In this In Box article, we share highlights from this first-person lessons learned from conducting three emerging area of research on SCAs. SCAs Vermont, Massachusetts, and Colorado, one municipal climate assessment (Boston), and a syn- LEARNING FROM GLOBAL AND NA- thesis of lessons learned from 40 years of conducting TIONAL ASSESSMENTS. Years of research on national and international CAs. The closed afternoon global and national CAs offers a number of impor- session focused on synthesizing lessons learned from tant lessons. First, research on global assessments SCAs. Presentation slides and notes from the workshop (Farrell and Jäger 2006) and the U.S. National CA helped inform development of the interview protocol. (NCA) (Mitchell et al. 2006) suggests that involving We sought and obtained Institutional Review recognized experts enhances assessment credibility Board approval for our qualitative research (protocol as does using accepted data, methods/tools, numerical X18-093) that involved interviews with 1–2 individu- models, and scientific peer review. Credibility of CAs als from 14 SCAs totaling 17 interviewees (Table 1). can be undermined when certain types of expertise Interviewees were identified using 1) the participant are excluded, when it is perceived that alarming and list from the National Academies Making Climate 2148 | NOVEMBER 2019 Brought to you by NOAA Central Library | Unauthenticated | Downloaded 07/13/21 12:17 PM UTCAssessments Work Workshop held in August 2018 and global assessments (see Fig. 2). Credible SCAs [National Academy of Sciences (NAS); NAS 2019], 2) rely both on recognized experts to perform the as- coauthor networks, and 3) snowball (from interview- sessment using accepted data and methods, and on ees) and internet searches for SCAs. Representatives scientific peer review of the assessment products from all 14 SCAs we contacted agreed to an interview (13 of 14 state assessments employed peer review). and all interviewees led or played major roles in their Where SCAs differ, they often require the production SCA. Interviews were conducted from October to of new knowledge to compensate for the scarcity of December 2018, by phone, and each interview lasted available scientific evidence at the state scale. While between 43 and 109 min. Interviewees were asked SCAs typically produce state-scale knowledge using questions about 1) the organization and conduct of existing data such as long-term, quality-controlled, the SCA (i.e., motivation, scope, funding, climate data weather station data to analyze historical climate and analysis, review process, stakeholder engagement, trends, or downscaled statistical [e.g., BCSD, Local- outreach, and use of SCA products); 2) stakeholder per- ized Constructed Analogs (LOCA)] and dynamical ceptions of SCA salience, credibility, and legitimacy; (e.g., NARCCAP; Mearns et al. 2013) models for and 3) challenges and lessons learned from doing the making climate projections, there is little guidance SCA building on themes from the literature (Cash et al. for how to appropriately apply this information at the 2003; Farrell and Jäger 2006; Mitchell et al. 2006; Vardy state scale. For example, in Connecticut, assessment et al. 2017). Interviews were transcribed and coded in authors sought to use the LOCA (Pierce et al. 2014) NVivo 11 (QSR International) using both inductive and database for consistency with the NCA, but verifica- deductive qualitative methodologies (Creswell 2007; tion with local climate observations showed that the Galletta 2013; Saldaña 2016). Because anonymity was Multivariate Adaptive Constructed Analogs (MACA; guaranteed, interviewees are referred to by code only. Abatzoglou and Brown 2012) database better matched See supplemental material for the interview protocol historical climate observations, especially for extreme and for additional details on research methods. precipitation statistics (Seth et al. 2019). Building support and buy-in through engagement SIMILARITIES AND DIFFERENCES IN EN- with policy-/decision-makers and other stakehold- SURING CREDIBLE, LEGITIMATE, AND ers was common among the 14 SCAs we reviewed. SALIENT ASSESSMENTS. Our own experience However, only two assessments considered legitimacy and the experience of our interviewees suggest that a core concern, focusing on the perceived fairness SCAs build credibility in similar ways to national of who participates and on perceptions about the intended audience. For SCAs, beyond engagement, legitimacy crucially depended on the in- volvement of local experts. One interviewee explained, “people were really very supportive of what we did because it…wasn’t somebody from another univer- sity or an academic somewhere else that was saying this kind of thing to the state. It was local experts with local expertise” (SCA interviewee 4). Salience depends on working with policy-/decision-makers in the production of assessment information and, similar to as- sessments at other scales, many Fig. 2. Comparison of both common and unique approaches to enhanc- of the 14 SCAs we reviewed ing credibility, legitimacy, and salience among international, national and engaged with state and local state CAs. policy-/decision-makers and AMERICAN METEOROLOGICAL SOCIETY NOVEMBER 2019 | 2149 Brought to you by NOAA Central Library | Unauthenticated | Downloaded 07/13/21 12:17 PM UTCother stakeholders. However, there was consider- using boundary organizations can help offset neces- able variation in who were engaged, how they were sary trade-offs. Boundary organizations can leverage engaged, and how often engagement happened. For both internal resources and staffing to help organize example, ongoing collaborations with local and state and conduct the assessment and external relationships decision-makers in the production of assessment with stakeholders to facilitate engagement. Their fa- information was a hallmark of the Vermont assess- miliarity with locally credible and salient datasets and ment, whereas Massachusetts used a more consultative models, along with a track record of coproduction can approach through periodic workshops and meetings streamline the production of new knowledge. with stakeholders and decision-makers. Colorado SCAs offer the promise of usable climate informa- fell in between seeking repeated input from policy-/ tion at the spatial and temporal scales decision-makers decision-makers and other stakeholders to direct the need, yet SCAs are challenged to deliver on this assessment scope, refocus efforts along the way, and promise because of inadequacies in the availability of review the final assessment. finescale, long-term historical climate information, Research shows that interactions between scien- shortcomings in the capability of climate models to tists and policy-/decision-makers through bound- project climate at fine spatial and temporal resolu- ary organizations—organizations that straddle the tions, and the lack of existing scholarship on climate science–policy divide, provide trusted information, impacts at the scale of interest. Many interviewees and establish and maintain relationships with mentioned a mismatch between the availability of decision-makers—improves salience and usability long-term historical climate data on which to base of climate information (Agrawala et al. 2001; Bales trends analysis and validation procedures, and the fine et al. 2004; Kirchhoff et al. 2013; McNie 2008). For spatial and temporal scales required by stakeholders. example, Colorado’s assessment relied on a boundary Another mismatch exists with global climate model organization, the Western Water Assessment (https:// simulations whose native spatial resolution (e.g., larger wwa.colorado.edu/about/index.html), to lead the than hundreds of kilometers; Masson and Knutti 2011) assessment and to facilitate communication and en- is generally much coarser than what stakeholders want gagement with stakeholders. In addition to Colorado, for making decisions about local climate impacts. four other SCAs relied on boundary organizations. Furthermore, uncertainties in finescale projections Interviews suggest that differences in the quality and are greater (Hawkins and Sutton 2009) contributing level of engagement may affect the salience and us- to spatially homogeneous projections despite geo- ability of assessment information, but it was difficult graphical differences (e.g., inland vs coast, mountain to separate the influence of engagement from other vs valley). Finally, several interviewees expressed chal- influential factors (e.g., motivation for assessment). lenges with the lack of existing scholarship on areas of interest to state stakeholders. For example, the lack of UNIQUE CHALLENGES OF STATE AS- a robust literature on climate impacts to public health, SESSMENTS. National and global CAs are relatively ecosystems, and agriculture prevented assessment well resourced with centralized staffing to assist in authors in two states from including climate impacts organization and outreach (Jacobs and Buizer 2016; information on critical sectors of interest to stakehold- Jabbour and Flachsland 2017), whereas SCAs often ers due to insufficient evidence. operate with limited human and financial resources Finally, the IPCC and NCA are mandated to recur and under short time lines. These factors necessitate at regular intervals, which fosters advancements in compromises between efforts to develop local scientific CAs and the incorporation of new information. The products, engage with the public, policy-makers, and latest generation of IPCC and NCA assessments are other stakeholders, and implement effective com- more participatory and cover a broader range of topics munication strategies. Our review suggests that SCAs and, over time, have generated deeper engagement and often invest the most time and resources in generating support for climate solutions (Jabbour and Flachsland new knowledge; only 2 of the 14 assessments invested 2017; Jacobs and Buizer 2016; Mach and Field 2017). heavily in engagement and communication in addition SCAs may or may not have an official mandate and to knowledge creation. Yet, rather than resource limita- few have support for a recurring assessment process. tions, philosophical differences in how to create SCA Among the 14 assessments reviewed, only three recur (e.g., valuing engagement and communication) drove with predictable regularity. In California, the longest- differences in this investment. Our review suggests that running example, changes include a broader range 2150 | NOVEMBER 2019 Brought to you by NOAA Central Library | Unauthenticated | Downloaded 07/13/21 12:17 PM UTCof topics, and an expansion in expertise type and makes sense (Galford et al. 2016; NAS 2019) as does stakeholders involved over time. For SCAs that lack more carefully examining SCAs to extract benefits support for a recurring assessment process, there are and drawbacks of different engagement approaches fewer opportunities for learning and change including to improve credibility, legitimacy, salience, and ul- shifts in engagement quality, capacity building, and timately the usability of information for local policy support for solutions. and decision-making. LEARNING FROM EXPERIENCE AND ACKNOWLEDGMENTS. Seth, Lombardo, Stephen- NEXT STEPS FOR STATE ASSESSMENTS. son, and Wang were supported by the Connecticut Institute There are important differences and challenges for Resilience and Climate Adaptation. Galford was sup- specific to SCAs that go beyond those of larger-scale ported by the Norman Foundation and Rubenstein School assessments including sparseness of existing literature of Environment and Natural Resources at the University for traditional assessment necessitating the produc- of Vermont. Karmalkar was supported by State of Massa- tion of new knowledge, little deliberate focus on fair- chusetts and Northeast Climate Adaptation Science Center ness in and representativeness of the assessment (a at UMass Amherst. Barlow was supported by the National traditional focus of legitimacy), a lack of support for Science Foundation (Award AGS-1623912). The authors an ongoing assessment process, short time lines and would also like to thank interviewees who graciously limited funding, and mismatches between the usable shared their time and experience. information stakeholders want and what state assess- ments can actually provide. Identifying and learning FOR FURTHER READING from these differences and challenges is important for guiding the next generation of SCAs. Lessons learned Abatzoglou, J. T., and T. J. Brown, 2012: A comparison from our experience and the experience of others in of statistical downscaling methods suited for wildfire creating SCAs include the following: applications. Int. J. Climatol., 32, 772–780, https:// doi.org/10.1002/joc.2312. • SCAs should make prioritize efforts to address Agrawala, S., K. Broad, and D. H. Guston, 2001: Integrat- legitimacy and consider credibility, legitimacy, and ing climate forecasts and societal decision making: salience as core criteria. Challenges to an emergent boundary organization. • Ongoing support for SCAs is needed. Lack of sup- Sci. Technol. Hum. Values, 26, 454–477, https://doi port for a recurring assessment process creates .org/10.1177/016224390102600404. fewer opportunities for learning and change and Bales, R. C., D. M. Liverman, and B. Morehouse, 2004: the associated shifts in the engagement quality, Integrated assessment as a step toward reducing cli- capacity building, and support for solutions. mate vulnerability in the southwestern United States. • SCAs should clearly identify the assessment Bull. Amer. Meteor. Soc., 85, 1727–1734, https://doi bounds, where resources will be used, and how .org/10.1175/BAMS-85-11-1727. trade-offs in the generation of new knowledge, Bierbaum, R., and Coauthors, 2013: A comprehensive engagement, and communication will be managed. review of climate adaptation in the United States: • Boundary organizations can help mitigate trade- More than before, but less than needed. Mitigation offs between the production of new knowledge, Adapt. Strategies Global Change, 18, 361–406, https:// engagement, and communication with policy-/ doi.org/10.1007/s11027-012-9423-1. decision-makers, other stakeholders and the public. Buizer, J. L., and Coauthors, 2016: Building a sustained • The lack of high-resolution observed and projected climate assessment process. Climatic Change, 135, data are key constraints for SCAs. 23–37, https://doi.org/10.1007/s10584-015-1501-4. Cash, D., W. C. Clark, F. Alcock, N. M. Dickson, While these lessons are a useful starting point for N. Eckley, and J. Jäger, 2003: Salience, credibility, future SCAs, more work is needed to fully understand legitimacy and boundaries: Linking research, assess- what makes SCAs effective and to inform both broad ment and decision making. Harvard University John and specific guidance for SCAs, such as technical F. Kennedy School of Government Faculty Working guidance on how to apply existing data appropriately Paper RWP02-046, 25 pp. at the state scale. In addition, building on existing Cloyd, E., S. C. Moser, E. Maibach, J. Maldonado, and networks and ongoing efforts to learn from SCAs C. Tinqiao, 2016: Engagement in the Third U.S. AMERICAN METEOROLOGICAL SOCIETY NOVEMBER 2019 | 2151 Brought to you by NOAA Central Library | Unauthenticated | Downloaded 07/13/21 12:17 PM UTCNational Climate Assessment: Commitment, capac- Ph.D. dissertation, University of Colorado Boulder, ity, and communication for impact. Climatic Change, 293 pp. 135, 39–54, https://doi.org/10.1007/s10584-015-1568-y. Mearns, L. O., and Coauthors, 2013: Climate change Creswell, J. W., 2007: Research Design: Qualitative, projections of the North American Regional Climate Quantitative and Mixed Method Approaches. SAGE Change Assessment Program (NARCCAP). Cli- Publications, 296 pp. matic Change, 120, 965–975, https://doi.org/10.1007 Farrell, A. E., and J. Jäger, 2006: Assessments of Regional /s10584-013-0831-3. and Global Environmental Risks: Designing Processes Mitchell, R. B., W. C. Clark, D. W. Cash, and N. M. for the Effective Use of Science in Decisionmaking. Dickson, 2006: Global Environmental Assessments: Resources for the Future Press, 320 pp. Information and Influence. MIT Press, 352 pp. Galford, G. L., and Coauthors, 2016: Bridging the cli- Morgan, M. G., and Coauthors, 2005: Learning from mate information gap: A framework for engaging the U.S. National Assessment of Climate Change Im- knowledge brokers and decision makers in state pacts. Environ. Sci. Technol., 39, 9023–9032, https:// climate assessments. Climatic Change, 138, 383–395, doi.org/10.1021/es050865i. https://doi.org/10.1007/s10584-016-1756-4. NAS, 2019: Making Climate Assessments Work: Learning Galletta, A., 2013. Mastering the Semi-Structured Inter- from California and Other Subnational Climate As- view and Beyond: From Research Design to Analysis sessments. National Academies Press, 86 pp., https:// and Publication. New York University Press, 258 pp. doi.org/10.17226/25324. Hawkins, E., and R. Sutton, 2009: The potential to Pearce, W., M. Mahony, and S. Raman, 2018: Science narrow uncertainty in regional climate predictions. advice for global challenges: Learning from trade- Bull. Amer. Meteor. Soc., 90, 1095–1108, https://doi offs in the IPCC. Environ. Sci. Policy, 80, 125–131, .org/10.1175/2009BAMS2607.1. https://doi.org/10.1016/j.envsci.2017.11.017. IPCC, 2014: Climate Change 2014: Synthesis Report. Pierce, D. W., D. R. Cayan, and B. L. Thrasher, 2014: R. K. Pachauri and L. A. Meyer, Eds., IPCC, 151 pp. Statistical downscaling using localized constructed Jabbour, J., and C. Flachsland, 2017: 40 years of global analogs (LOCA). J. Hydrometeor., 15, 2558–2585, environmental assessments: A retrospective Analy- https://doi.org/10.1175/JHM-D-14-0082.1. sis. Environ. Sci. Policy, 77, 193–202, https://doi Saldaña, J., 2016: The Coding Manual for Qualitative .org/10.1016/j.envsci.2017.05.001. Researchers. SAGE Publishing, 328 pp. Jacobs, K. L., and J. L. Buizer, 2016: Building community, Seth, A., G. Wang, C. Kirchhoff, K. Lombardo, credibility and knowledge: The third US National S. Stephenson, R. Anyah, and J. Wu, 2019: Con- Climate Assessment. Climatic Change, 135, 9–22, necticut Physical Climate Science Assessment https://doi.org/10.1007/s10584-015-1445-8. Report (PCSAR): Observed trends and projections Kirchhoff, C. J., M. C. Lemos, and S. Dessai, 2013: Ac- of temperature and precipitation. Connecticut In- tionable knowledge for environmental decision mak- stitute for Resilience and Climate Adaptation, 68 ing. Annu. Rev. Environ. Resour., 38, 393–414, https:// pp., https://circa.uconn.edu/wp-content/uploads doi.org/10.1146/annurev-environ-022112-112828. /sites/1618/2019/08/CTPCSAR-Aug2019.pdf. Mach, K. J., and C. B. Field, 2017: Toward the next USGCRP, 2017: Climate Science Special Report: Fourth generation of assessment. Annu. Rev. Environ. Re- National Climate Assessment. Vol. I. D. J. Wuebbles sour., 42, 569–597, https://doi.org/10.1146/annurev et al., Eds., U.S. Global Change Research Program, -environ-102016-061007. 470 pp., https://doi.org/10.7930/J0J964J6. Masson, D., and R. Knutti, 2011: Spatial-scale depen- Vardy, M., M. Oppenheimer, N. K. Dubash, J. O’Reilly, dence of climate model performance in the CMIP3 and D. Jamieson, 2017: The Intergovernmental Panel ensemble. J. Climate, 24, 2680–2692, https://doi on Climate Change: Challenges and opportunities. .org/10.1175/2011JCLI3513.1. Annu. Rev. Environ. Resour., 42, 55–75, https://doi McNie, E. C., 2008: Co-producing useful climate sci- .org/10.1146/annurev-environ-102016-061053. ence for policy: Lessons from the RISA program. 2152 | NOVEMBER 2019 Brought to you by NOAA Central Library | Unauthenticated | Downloaded 07/13/21 12:17 PM UTC",
    "TEXT BY PAGE": [
        "Climate Assessments for Local Action chriStine J. Kirchhoff, JoSeph J. BarSugli, gillian l. galford, amBariSh V. KarmalKar, Kelly lomBardo, Scott r. StephenSon, matheW BarloW, anJi Seth, guiling Wang, and auStin franK W hile climate change is a global phenomenon, the associated impacts such as heat waves, droughts, wildfires, and storms are dev- astating to local communities [U.S. Global Change Research Program (USGCRP) 2017]. The frequency and severity of these events have renewed interest in better understanding local impacts and adaptation options (Bierbaum et al. 2013). As states and communities’ interest in climate change impacts and ad- aptation grows, so does their need Fig. 1. Scale, purpose, and audience of global, national, and state CAs. for usable climate information. Global and national climate assessments (CAs) under the auspices of the Intergovernmental Panel are comprehensive, authoritative sources of informa- on Climate Change (IPCC) and USGCRP involving tion about observed and projected climate changes synthesis and evaluation of scientific studies by hun- and their impacts on society, like those undertaken dreds (or thousands) of recognized experts (IPCC 2014; USGCRP 2017). Assessments aim to produce credible, legitimate, policy-relevant, scientific information to AFFILIATIONS: Kirchhoff, StephenSon, Seth, Wang, and inform policy and decisions (Farrell and Jäger 2006; franK—University of Connecticut, Storrs, Connecticut; Jacobs and Buizer 2016; Mach and Field 2017; Mitchell BarSugli—Cooperative Institute for Research in Environmental et al. 2006). Unfortunately, there remains a disconnect Sciences, University of Colorado Boulder, and NOAA/ESRL/ between the information in these global and national PSD, Boulder, Colorado; galford—University of Vermont, CAs and what states and communities need to inform Burlington, Vermont; KarmalKar—Northeast Climate Adaptation Science Center, and University of Massachusetts local decision-making (see Fig. 1). Amherst, Amherst, Massachusetts; lomBardo—University of To address this disconnect, more and more states Connecticut, Groton, Connecticut; BarloW—University of are undertaking CAs (see Table 1, and for more in- Massachusetts Lowell, Lowell, Massachusetts formation, see supplemental Table ES1) but with little CORRESPONDING AUTHOR: Christine J. Kirchhoff, guidance for how to organize and conduct compre- christine.kirchhoff@uconn.edu hensive, authoritative, and usable assessments at this The abstract for this article can be found in this issue, following the scale. While 40 years of research on global and na- table of contents. tional assessments provides a starting point to guide DOI:10.1175/BAMS-D-18-0138.1 state climate assessment (SCA) efforts to produce A supplement to this article is available online (10.1175/BAMS-D-18-0138.2) credible, legitimate, and policy-relevant information, there are unique aspects of state assessments that ©2019 American Meteorological Society fall outside the range of techniques used to develop For information regarding reuse of this content and general copyright information, consult the AMS Copyright Policy. assessments at larger scales. To address the need for comprehensive SCA guidance, the authors convened AMERICAN METEOROLOGICAL SOCIETY NOVEMBER 2019 | 2147 Brought to you by NOAA Central Library | Unauthenticated | Downloaded 07/13/21 12:17 PM UTC",
        "Table 1. States with SCAs with most recent SCA year. controversial findings are excluded, and Interviewees included representatives from all SCAs listed when political forces try to delegitimize or except Maryland and Delaware. discredit the assessment (Morgan et al. 2005; Vardy et al. 2017). Second, being transparent, State Year State Year ensuring fair participation, and engaging published published with policy- and decision-makers and the Delaware 2014 Nebraska 2014 general public enhances legitimacy resulting in buy-in and support for CAs (Farrell and California 2018 New Mexico 2005 Jäger 2006; Mitchell et al. 2006; Mach and Colorado 2014 New York 2011 Field 2017; Vardy et al. 2017). For example, consistent engagement with national govern- Connecticut — Oregon 2019 ment representatives during the IPCC AR4 Pacific Islands 2012 Pennsylvania 2015 enhanced legitimacy and created support Indiana 2018 Rhode Island1 2017 for the assessment (Vardy et al. 2017), while opportunities for both public and stakeholder Maryland 2018 Vermont 2014 input enhanced legitimacy of the third U.S. Massachusetts 2018 Washington 2013 NCA (Cloyd et al. 2016). Finally, salience is about the relevance of assessment informa- Montana 2017 Wisconsin 2011 tion for decision-making or the public (Cash 1 The Rhode Island state climate summary is one of 50 state summaries pro- et al. 2003). Scholars of global and national duced by NCICS. assessments suggest that achieving salience requires engaging with policy- and decision- a workshop (November 2017) at which participants makers in the production of assessment information discussed lessons learned beyond review of the litera- and using effective and varied communication strate- ture on global and national CAs, as well as from their gies (Buizer et al. 2016; Farrell and Jäger 2006; Mach experiences conducting four SCAs—Connecticut, and Field 2017; Mitchell et al. 2006; Pearce et al. 2018). Vermont, Massachusetts, and Colorado. In 2018, the authors conducted interviews to learn from the LEARNING FROM STATE CLIMATE AS- experiences of 10 additional U.S. SCAs. Drawing on SESSMENTS: WORKSHOP AND INTER- the literature and firsthand experience of the authors VIEWS. The authors convened “Methodologies and and interview participants, we sought to understand Engagement for State Level Climate Assessment” on 1) how global and national CAs produce credible, 6 November 2017 at the University of Connecticut, legitimate, and salient scientific information to help Storrs campus. Approximately 25 individuals includ- guide SCAs; 2) similarities and differences between ing the authors and other faculty, staff, and students assessments at state and other scales; 3) unique chal- from the University of Connecticut participated in lenges faced by SCAs; and 4) lessons learned from the event. The open portion of the event included five existing SCAs that may help guide future assessments. presentations and a panel discussion designed to share In this In Box article, we share highlights from this first-person lessons learned from conducting three emerging area of research on SCAs. SCAs Vermont, Massachusetts, and Colorado, one municipal climate assessment (Boston), and a syn- LEARNING FROM GLOBAL AND NA- thesis of lessons learned from 40 years of conducting TIONAL ASSESSMENTS. Years of research on national and international CAs. The closed afternoon global and national CAs offers a number of impor- session focused on synthesizing lessons learned from tant lessons. First, research on global assessments SCAs. Presentation slides and notes from the workshop (Farrell and Jäger 2006) and the U.S. National CA helped inform development of the interview protocol. (NCA) (Mitchell et al. 2006) suggests that involving We sought and obtained Institutional Review recognized experts enhances assessment credibility Board approval for our qualitative research (protocol as does using accepted data, methods/tools, numerical X18-093) that involved interviews with 1–2 individu- models, and scientific peer review. Credibility of CAs als from 14 SCAs totaling 17 interviewees (Table 1). can be undermined when certain types of expertise Interviewees were identified using 1) the participant are excluded, when it is perceived that alarming and list from the National Academies Making Climate 2148 | NOVEMBER 2019 Brought to you by NOAA Central Library | Unauthenticated | Downloaded 07/13/21 12:17 PM UTC",
        "Assessments Work Workshop held in August 2018 and global assessments (see Fig. 2). Credible SCAs [National Academy of Sciences (NAS); NAS 2019], 2) rely both on recognized experts to perform the as- coauthor networks, and 3) snowball (from interview- sessment using accepted data and methods, and on ees) and internet searches for SCAs. Representatives scientific peer review of the assessment products from all 14 SCAs we contacted agreed to an interview (13 of 14 state assessments employed peer review). and all interviewees led or played major roles in their Where SCAs differ, they often require the production SCA. Interviews were conducted from October to of new knowledge to compensate for the scarcity of December 2018, by phone, and each interview lasted available scientific evidence at the state scale. While between 43 and 109 min. Interviewees were asked SCAs typically produce state-scale knowledge using questions about 1) the organization and conduct of existing data such as long-term, quality-controlled, the SCA (i.e., motivation, scope, funding, climate data weather station data to analyze historical climate and analysis, review process, stakeholder engagement, trends, or downscaled statistical [e.g., BCSD, Local- outreach, and use of SCA products); 2) stakeholder per- ized Constructed Analogs (LOCA)] and dynamical ceptions of SCA salience, credibility, and legitimacy; (e.g., NARCCAP; Mearns et al. 2013) models for and 3) challenges and lessons learned from doing the making climate projections, there is little guidance SCA building on themes from the literature (Cash et al. for how to appropriately apply this information at the 2003; Farrell and Jäger 2006; Mitchell et al. 2006; Vardy state scale. For example, in Connecticut, assessment et al. 2017). Interviews were transcribed and coded in authors sought to use the LOCA (Pierce et al. 2014) NVivo 11 (QSR International) using both inductive and database for consistency with the NCA, but verifica- deductive qualitative methodologies (Creswell 2007; tion with local climate observations showed that the Galletta 2013; Saldaña 2016). Because anonymity was Multivariate Adaptive Constructed Analogs (MACA; guaranteed, interviewees are referred to by code only. Abatzoglou and Brown 2012) database better matched See supplemental material for the interview protocol historical climate observations, especially for extreme and for additional details on research methods. precipitation statistics (Seth et al. 2019). Building support and buy-in through engagement SIMILARITIES AND DIFFERENCES IN EN- with policy-/decision-makers and other stakehold- SURING CREDIBLE, LEGITIMATE, AND ers was common among the 14 SCAs we reviewed. SALIENT ASSESSMENTS. Our own experience However, only two assessments considered legitimacy and the experience of our interviewees suggest that a core concern, focusing on the perceived fairness SCAs build credibility in similar ways to national of who participates and on perceptions about the intended audience. For SCAs, beyond engagement, legitimacy crucially depended on the in- volvement of local experts. One interviewee explained, “people were really very supportive of what we did because it…wasn’t somebody from another univer- sity or an academic somewhere else that was saying this kind of thing to the state. It was local experts with local expertise” (SCA interviewee 4). Salience depends on working with policy-/decision-makers in the production of assessment information and, similar to as- sessments at other scales, many Fig. 2. Comparison of both common and unique approaches to enhanc- of the 14 SCAs we reviewed ing credibility, legitimacy, and salience among international, national and engaged with state and local state CAs. policy-/decision-makers and AMERICAN METEOROLOGICAL SOCIETY NOVEMBER 2019 | 2149 Brought to you by NOAA Central Library | Unauthenticated | Downloaded 07/13/21 12:17 PM UTC",
        "other stakeholders. However, there was consider- using boundary organizations can help offset neces- able variation in who were engaged, how they were sary trade-offs. Boundary organizations can leverage engaged, and how often engagement happened. For both internal resources and staffing to help organize example, ongoing collaborations with local and state and conduct the assessment and external relationships decision-makers in the production of assessment with stakeholders to facilitate engagement. Their fa- information was a hallmark of the Vermont assess- miliarity with locally credible and salient datasets and ment, whereas Massachusetts used a more consultative models, along with a track record of coproduction can approach through periodic workshops and meetings streamline the production of new knowledge. with stakeholders and decision-makers. Colorado SCAs offer the promise of usable climate informa- fell in between seeking repeated input from policy-/ tion at the spatial and temporal scales decision-makers decision-makers and other stakeholders to direct the need, yet SCAs are challenged to deliver on this assessment scope, refocus efforts along the way, and promise because of inadequacies in the availability of review the final assessment. finescale, long-term historical climate information, Research shows that interactions between scien- shortcomings in the capability of climate models to tists and policy-/decision-makers through bound- project climate at fine spatial and temporal resolu- ary organizations—organizations that straddle the tions, and the lack of existing scholarship on climate science–policy divide, provide trusted information, impacts at the scale of interest. Many interviewees and establish and maintain relationships with mentioned a mismatch between the availability of decision-makers—improves salience and usability long-term historical climate data on which to base of climate information (Agrawala et al. 2001; Bales trends analysis and validation procedures, and the fine et al. 2004; Kirchhoff et al. 2013; McNie 2008). For spatial and temporal scales required by stakeholders. example, Colorado’s assessment relied on a boundary Another mismatch exists with global climate model organization, the Western Water Assessment (https:// simulations whose native spatial resolution (e.g., larger wwa.colorado.edu/about/index.html), to lead the than hundreds of kilometers; Masson and Knutti 2011) assessment and to facilitate communication and en- is generally much coarser than what stakeholders want gagement with stakeholders. In addition to Colorado, for making decisions about local climate impacts. four other SCAs relied on boundary organizations. Furthermore, uncertainties in finescale projections Interviews suggest that differences in the quality and are greater (Hawkins and Sutton 2009) contributing level of engagement may affect the salience and us- to spatially homogeneous projections despite geo- ability of assessment information, but it was difficult graphical differences (e.g., inland vs coast, mountain to separate the influence of engagement from other vs valley). Finally, several interviewees expressed chal- influential factors (e.g., motivation for assessment). lenges with the lack of existing scholarship on areas of interest to state stakeholders. For example, the lack of UNIQUE CHALLENGES OF STATE AS- a robust literature on climate impacts to public health, SESSMENTS. National and global CAs are relatively ecosystems, and agriculture prevented assessment well resourced with centralized staffing to assist in authors in two states from including climate impacts organization and outreach (Jacobs and Buizer 2016; information on critical sectors of interest to stakehold- Jabbour and Flachsland 2017), whereas SCAs often ers due to insufficient evidence. operate with limited human and financial resources Finally, the IPCC and NCA are mandated to recur and under short time lines. These factors necessitate at regular intervals, which fosters advancements in compromises between efforts to develop local scientific CAs and the incorporation of new information. The products, engage with the public, policy-makers, and latest generation of IPCC and NCA assessments are other stakeholders, and implement effective com- more participatory and cover a broader range of topics munication strategies. Our review suggests that SCAs and, over time, have generated deeper engagement and often invest the most time and resources in generating support for climate solutions (Jabbour and Flachsland new knowledge; only 2 of the 14 assessments invested 2017; Jacobs and Buizer 2016; Mach and Field 2017). heavily in engagement and communication in addition SCAs may or may not have an official mandate and to knowledge creation. Yet, rather than resource limita- few have support for a recurring assessment process. tions, philosophical differences in how to create SCA Among the 14 assessments reviewed, only three recur (e.g., valuing engagement and communication) drove with predictable regularity. In California, the longest- differences in this investment. Our review suggests that running example, changes include a broader range 2150 | NOVEMBER 2019 Brought to you by NOAA Central Library | Unauthenticated | Downloaded 07/13/21 12:17 PM UTC",
        "of topics, and an expansion in expertise type and makes sense (Galford et al. 2016; NAS 2019) as does stakeholders involved over time. For SCAs that lack more carefully examining SCAs to extract benefits support for a recurring assessment process, there are and drawbacks of different engagement approaches fewer opportunities for learning and change including to improve credibility, legitimacy, salience, and ul- shifts in engagement quality, capacity building, and timately the usability of information for local policy support for solutions. and decision-making. LEARNING FROM EXPERIENCE AND ACKNOWLEDGMENTS. Seth, Lombardo, Stephen- NEXT STEPS FOR STATE ASSESSMENTS. son, and Wang were supported by the Connecticut Institute There are important differences and challenges for Resilience and Climate Adaptation. Galford was sup- specific to SCAs that go beyond those of larger-scale ported by the Norman Foundation and Rubenstein School assessments including sparseness of existing literature of Environment and Natural Resources at the University for traditional assessment necessitating the produc- of Vermont. Karmalkar was supported by State of Massa- tion of new knowledge, little deliberate focus on fair- chusetts and Northeast Climate Adaptation Science Center ness in and representativeness of the assessment (a at UMass Amherst. Barlow was supported by the National traditional focus of legitimacy), a lack of support for Science Foundation (Award AGS-1623912). The authors an ongoing assessment process, short time lines and would also like to thank interviewees who graciously limited funding, and mismatches between the usable shared their time and experience. information stakeholders want and what state assess- ments can actually provide. Identifying and learning FOR FURTHER READING from these differences and challenges is important for guiding the next generation of SCAs. Lessons learned Abatzoglou, J. T., and T. J. Brown, 2012: A comparison from our experience and the experience of others in of statistical downscaling methods suited for wildfire creating SCAs include the following: applications. Int. J. Climatol., 32, 772–780, https:// doi.org/10.1002/joc.2312. • SCAs should make prioritize efforts to address Agrawala, S., K. Broad, and D. H. Guston, 2001: Integrat- legitimacy and consider credibility, legitimacy, and ing climate forecasts and societal decision making: salience as core criteria. Challenges to an emergent boundary organization. • Ongoing support for SCAs is needed. Lack of sup- Sci. Technol. Hum. Values, 26, 454–477, https://doi port for a recurring assessment process creates .org/10.1177/016224390102600404. fewer opportunities for learning and change and Bales, R. C., D. M. Liverman, and B. Morehouse, 2004: the associated shifts in the engagement quality, Integrated assessment as a step toward reducing cli- capacity building, and support for solutions. mate vulnerability in the southwestern United States. • SCAs should clearly identify the assessment Bull. Amer. Meteor. Soc., 85, 1727–1734, https://doi bounds, where resources will be used, and how .org/10.1175/BAMS-85-11-1727. trade-offs in the generation of new knowledge, Bierbaum, R., and Coauthors, 2013: A comprehensive engagement, and communication will be managed. review of climate adaptation in the United States: • Boundary organizations can help mitigate trade- More than before, but less than needed. Mitigation offs between the production of new knowledge, Adapt. Strategies Global Change, 18, 361–406, https:// engagement, and communication with policy-/ doi.org/10.1007/s11027-012-9423-1. decision-makers, other stakeholders and the public. Buizer, J. L., and Coauthors, 2016: Building a sustained • The lack of high-resolution observed and projected climate assessment process. Climatic Change, 135, data are key constraints for SCAs. 23–37, https://doi.org/10.1007/s10584-015-1501-4. Cash, D., W. C. Clark, F. Alcock, N. M. Dickson, While these lessons are a useful starting point for N. Eckley, and J. Jäger, 2003: Salience, credibility, future SCAs, more work is needed to fully understand legitimacy and boundaries: Linking research, assess- what makes SCAs effective and to inform both broad ment and decision making. Harvard University John and specific guidance for SCAs, such as technical F. Kennedy School of Government Faculty Working guidance on how to apply existing data appropriately Paper RWP02-046, 25 pp. at the state scale. In addition, building on existing Cloyd, E., S. C. Moser, E. Maibach, J. Maldonado, and networks and ongoing efforts to learn from SCAs C. Tinqiao, 2016: Engagement in the Third U.S. AMERICAN METEOROLOGICAL SOCIETY NOVEMBER 2019 | 2151 Brought to you by NOAA Central Library | Unauthenticated | Downloaded 07/13/21 12:17 PM UTC",
        "National Climate Assessment: Commitment, capac- Ph.D. dissertation, University of Colorado Boulder, ity, and communication for impact. Climatic Change, 293 pp. 135, 39–54, https://doi.org/10.1007/s10584-015-1568-y. Mearns, L. O., and Coauthors, 2013: Climate change Creswell, J. W., 2007: Research Design: Qualitative, projections of the North American Regional Climate Quantitative and Mixed Method Approaches. SAGE Change Assessment Program (NARCCAP). Cli- Publications, 296 pp. matic Change, 120, 965–975, https://doi.org/10.1007 Farrell, A. E., and J. Jäger, 2006: Assessments of Regional /s10584-013-0831-3. and Global Environmental Risks: Designing Processes Mitchell, R. B., W. C. Clark, D. W. Cash, and N. M. for the Effective Use of Science in Decisionmaking. Dickson, 2006: Global Environmental Assessments: Resources for the Future Press, 320 pp. Information and Influence. MIT Press, 352 pp. Galford, G. L., and Coauthors, 2016: Bridging the cli- Morgan, M. G., and Coauthors, 2005: Learning from mate information gap: A framework for engaging the U.S. National Assessment of Climate Change Im- knowledge brokers and decision makers in state pacts. Environ. Sci. Technol., 39, 9023–9032, https:// climate assessments. Climatic Change, 138, 383–395, doi.org/10.1021/es050865i. https://doi.org/10.1007/s10584-016-1756-4. NAS, 2019: Making Climate Assessments Work: Learning Galletta, A., 2013. Mastering the Semi-Structured Inter- from California and Other Subnational Climate As- view and Beyond: From Research Design to Analysis sessments. National Academies Press, 86 pp., https:// and Publication. New York University Press, 258 pp. doi.org/10.17226/25324. Hawkins, E., and R. Sutton, 2009: The potential to Pearce, W., M. Mahony, and S. Raman, 2018: Science narrow uncertainty in regional climate predictions. advice for global challenges: Learning from trade- Bull. Amer. Meteor. Soc., 90, 1095–1108, https://doi offs in the IPCC. Environ. Sci. Policy, 80, 125–131, .org/10.1175/2009BAMS2607.1. https://doi.org/10.1016/j.envsci.2017.11.017. IPCC, 2014: Climate Change 2014: Synthesis Report. Pierce, D. W., D. R. Cayan, and B. L. Thrasher, 2014: R. K. Pachauri and L. A. Meyer, Eds., IPCC, 151 pp. Statistical downscaling using localized constructed Jabbour, J., and C. Flachsland, 2017: 40 years of global analogs (LOCA). J. Hydrometeor., 15, 2558–2585, environmental assessments: A retrospective Analy- https://doi.org/10.1175/JHM-D-14-0082.1. sis. Environ. Sci. Policy, 77, 193–202, https://doi Saldaña, J., 2016: The Coding Manual for Qualitative .org/10.1016/j.envsci.2017.05.001. Researchers. SAGE Publishing, 328 pp. Jacobs, K. L., and J. L. Buizer, 2016: Building community, Seth, A., G. Wang, C. Kirchhoff, K. Lombardo, credibility and knowledge: The third US National S. Stephenson, R. Anyah, and J. Wu, 2019: Con- Climate Assessment. Climatic Change, 135, 9–22, necticut Physical Climate Science Assessment https://doi.org/10.1007/s10584-015-1445-8. Report (PCSAR): Observed trends and projections Kirchhoff, C. J., M. C. Lemos, and S. Dessai, 2013: Ac- of temperature and precipitation. Connecticut In- tionable knowledge for environmental decision mak- stitute for Resilience and Climate Adaptation, 68 ing. Annu. Rev. Environ. Resour., 38, 393–414, https:// pp., https://circa.uconn.edu/wp-content/uploads doi.org/10.1146/annurev-environ-022112-112828. /sites/1618/2019/08/CTPCSAR-Aug2019.pdf. Mach, K. J., and C. B. Field, 2017: Toward the next USGCRP, 2017: Climate Science Special Report: Fourth generation of assessment. Annu. Rev. Environ. Re- National Climate Assessment. Vol. I. D. J. Wuebbles sour., 42, 569–597, https://doi.org/10.1146/annurev et al., Eds., U.S. Global Change Research Program, -environ-102016-061007. 470 pp., https://doi.org/10.7930/J0J964J6. Masson, D., and R. Knutti, 2011: Spatial-scale depen- Vardy, M., M. Oppenheimer, N. K. Dubash, J. O’Reilly, dence of climate model performance in the CMIP3 and D. Jamieson, 2017: The Intergovernmental Panel ensemble. J. Climate, 24, 2680–2692, https://doi on Climate Change: Challenges and opportunities. .org/10.1175/2011JCLI3513.1. Annu. Rev. Environ. Resour., 42, 55–75, https://doi McNie, E. C., 2008: Co-producing useful climate sci- .org/10.1146/annurev-environ-102016-061053. ence for policy: Lessons from the RISA program. 2152 | NOVEMBER 2019 Brought to you by NOAA Central Library | Unauthenticated | Downloaded 07/13/21 12:17 PM UTC"
    ]
}
all_unique_towns <- unique(ll3)
all_unique_towns
#
ll3
# Preview the place names
length(place_names[[1]])
library(readr)
library(tidyverse)
library(ggforce)
library(janitor)
library(sf)
library(gtable)
library(grid)
library(gridExtra)
library(tigris)
library(leaflet)
#adjust based on your computer
# my_dir <- "/Users/allisonjames/Desktop/bu/acresNLP/"
my_dir <- "/Users/cwm/Documents/GitHub/acresNLP/"
create_df <- function(filename){
data <- read_delim(filename)
return(data)
}
#combined table missing all arlington/belmont and some chelsea/everett
combined_table <- create_df(paste0(my_dir, "combined_output_v2.tsv"))
combined_table <- combined_table %>% clean_names()
combined_table$town_name <- gsub("url\\d+|\\d+|\\.json", "",
combined_table$file_name)
combined_table$town_name <- toupper(combined_table$town_name)
mystic_towns_list = c("Burlington", "Lexington", "Belmont", "Watertown",
"Arlington", "Winchester", "Woburn", "Reading",
"Stoneham", "Medford", "Somerville", "Cambridge",
"Boston", "Charlestown", "Everett", "Malden", "Melrose",
"Wakefield", "Chelsea", "Revere", "Winthrop", "Wilmington")
##
combined_table <- combined_table %>%
mutate(ACRES_town = (most_common_town %in% mystic_towns_list))
# stoneham is missing from this table !
head(combined_table)
#combined table missing all arlington/belmont and some chelsea/everett
combined_table <- create_df(paste0(my_dir, "combined_output_v2.tsv"))
combined_table <- combined_table %>% clean_names()
combined_table$town_name <- gsub("url\\d+|\\d+|\\.json", "",
combined_table$file_name)
combined_table$town_name <- toupper(combined_table$town_name)
mystic_towns_list = c("Burlington", "Lexington", "Belmont", "Watertown",
"Arlington", "Winchester", "Woburn", "Reading",
"Stoneham", "Medford", "Somerville", "Cambridge",
"Boston", "Charlestown", "Everett", "Malden", "Melrose",
"Wakefield", "Chelsea", "Revere", "Winthrop", "Wilmington")
##
combined_table <- combined_table %>%
mutate(is_ACRES_town = (most_common_town %in% mystic_towns_list))
table(combined_table$is_ACRES_town)
##
combined_table <- combined_table %>%
mutate(is_ACRES_town = (most_common_town %in% mystic_towns_list),
is_MASS = (most_common_stat == 'Massachusetts'))
##
combined_table <- combined_table %>%
mutate(is_ACRES_town = (most_common_town %in% mystic_towns_list),
is_MASS = (most_common_state == 'Massachusetts'))
table(combined_table$is_ACRES_town)
table(combined_table$is_MASS)
##
combined_table <- combined_table %>%
mutate(is_ACRES_town = (most_common_town %in% mystic_towns_list),
is_MASS = (most_common_state == 'Massachusetts'),
is_VALID = is_ACRES_town & is_MASS)
table(combined_table$is_VALID)
library(readr)
library(tidyverse)
library(ggforce)
library(janitor)
library(sf)
library(gtable)
library(grid)
library(gridExtra)
library(tigris)
library(leaflet)
### NOTES
# * STONEHAM HAS NO CLIMATE REPORTS
# * NOT A LOT OF ADJACENCY IN HAZARDS
#
# *
# * allison: for both hazards and outreach, for some towns the totals are < 100%
# * chad: expanding heat search terms and seeing if that changes things, manual search
# Needs:
# * Map
# * table of the heatmap with %s and n
# * REVERE AND LEXINGTON DON'T HAVE 100% in relevancy table
# * WHY ISNT HEAT MORE ** SEARCH TERMS
#
# * WHAT ABOUT THE COMMUNITY CONCERNS
# ----------------------------------------------------------------------------
#### create dataframe of hazard counts and proportions by town ####
#adjust based on your computer
# my_dir <- "/Users/allisonjames/Desktop/bu/acresNLP/"
my_dir <- "/Users/cwm/Documents/GitHub/acresNLP/"
create_df <- function(filename){
data <- read_delim(filename)
return(data)
}
#combined table missing all arlington/belmont and some chelsea/everett
combined_table <- create_df(paste0(my_dir, "combined_output_v2.tsv"))
combined_table <- combined_table %>% clean_names()
combined_table$town_name <- gsub("url\\d+|\\d+|\\.json", "",
combined_table$file_name)
combined_table$town_name <- toupper(combined_table$town_name)
mystic_towns_list = c("Burlington", "Lexington", "Belmont", "Watertown",
"Arlington", "Winchester", "Woburn", "Reading",
"Stoneham", "Medford", "Somerville", "Cambridge",
"Boston", "Charlestown", "Everett", "Malden", "Melrose",
"Wakefield", "Chelsea", "Revere", "Winthrop", "Wilmington")
##
combined_table <- combined_table %>%
mutate(is_ACRES_town = (most_common_town %in% mystic_towns_list),
is_MASS = (most_common_state == 'Massachusetts'))
combined_table <- combined_table %>%
mutate(pass_checks2 = (
is_ACRES_town == T &
is_MASS == T &
has_climate == 1 &
has_community == 1
))
table(combined_table$pass_checks2)
write_tsv(combined_table, 'combined_table_v2.tsv')
mancx <- read_tsv("manual_checks.txt")
mancx <- read.table("manual_checks.txt", header = F)
mancx <- read.table("manual_checks.txt", header = F, sep = " ")
mancx <- read.csv("manual_checks.csv")
head(mancx)
mancx <- read.csv("manual_checks.csv", header = T)
mancx <- read.csv("manual_checks.csv", header = F)
head(mancx)
combined_table
combined_table <- combined_table %>% left_join(mancx,
by = join_by(file_name == V7))
dim(combined_table)
write_tsv(combined_table, 'combined_table_v2.tsv')
table(combined_table$pass_checks2, combined_table$most_common_town)
table(combined_table$most_common_town, combined_table$pass_checks2)
library(readr)
library(tidyverse)
library(ggforce)
library(janitor)
library(sf)
library(gtable)
library(grid)
library(gridExtra)
library(tigris)
library(leaflet)
### NOTES
# * STONEHAM HAS NO CLIMATE REPORTS
# * NOT A LOT OF ADJACENCY IN HAZARDS
#
# *
# * allison: for both hazards and outreach, for some towns the totals are < 100%
# * chad: expanding heat search terms and seeing if that changes things, manual search
# Needs:
# * Map
# * table of the heatmap with %s and n
# * REVERE AND LEXINGTON DON'T HAVE 100% in relevancy table
# * WHY ISNT HEAT MORE ** SEARCH TERMS
#
# * WHAT ABOUT THE COMMUNITY CONCERNS
# ----------------------------------------------------------------------------
#### create dataframe of hazard counts and proportions by town ####
#adjust based on your computer
# my_dir <- "/Users/allisonjames/Desktop/bu/acresNLP/"
my_dir <- "/Users/cwm/Documents/GitHub/acresNLP/"
create_df <- function(filename){
data <- read_delim(filename)
return(data)
}
#combined table missing all arlington/belmont and some chelsea/everett
combined_table <- create_df(paste0(my_dir, "combined_output_v2.tsv"))
combined_table <- combined_table %>% clean_names()
combined_table$town_name <- gsub("url\\d+|\\d+|\\.json", "",
combined_table$file_name)
combined_table$town_name <- toupper(combined_table$town_name)
mystic_towns_list = c("Burlington", "Lexington", "Belmont", "Watertown",
"Arlington", "Winchester", "Woburn", "Reading",
"Stoneham", "Medford", "Somerville", "Cambridge",
"Boston", "Charlestown", "Everett", "Malden", "Melrose",
"Wakefield", "Chelsea", "Revere", "Winthrop", "Wilmington")
##
combined_table <- combined_table %>%
mutate(is_ACRES_town = (most_common_town %in% mystic_towns_list),
is_MASS = (most_common_state == 'Massachusetts'))
combined_table <- combined_table %>%
mutate(pass_checks2 = (
is_ACRES_town == T &
is_MASS == T &
has_climate == 1 &
has_community == 1
))
combined_table
table(combined_table$most_common_town, combined_table$pass_checks2)
mystic_towns_list = c("Burlington", "Lexington", "Belmont", "Watertown",
"Arlington", "Winchester", "Woburn", "Reading",
"Stoneham", "Medford", "Somerville", "Cambridge",
"Boston", "Charlestown", "Everett", "Malden", "Melrose",
"Wakefield", "Chelsea", "Revere", "Winthrop", "Wilmington")
##
combined_table <- combined_table %>%
mutate(is_ACRES_town = (most_common_town %in% tolower(mystic_towns_list)),
is_MASS = (most_common_state == 'massachusetts'))
combined_table <- combined_table %>%
mutate(pass_checks2 = (
is_ACRES_town == T &
is_MASS == T &
has_climate == 1 &
has_community == 1
))
combined_table
table(combined_table$most_common_town, combined_table$pass_checks2)
table(combined_table$pass_checks2)
mancx <- read.csv("manual_checks.csv", header = F)
head(mancx)
combined_table <- combined_table %>% left_join(mancx,
by = join_by(file_name == V7))
dim(combined_table)
write_tsv(combined_table, 'combined_table_v2.tsv')
dim(combined_table)
data.frame(head(combined_table))
write_tsv(combined_table, 'combined_table_v2.tsv')
pass_checks <- combined_table %>%
filter(pass_checks2) %>%
group_by(town_name) %>% tally()
pass_checks
pass_checks <- combined_table %>%
filter(pass_checks2) %>%
group_by(most_common_town) %>% tally()
pass_checks
# ----------------------------------------------------------------------------
#90% or over for all towns
combined_table_relevant <- combined_table %>%
filter(pass_checks2)
dim(combined_table)
dim(combined_table_relevant)
hazard_by_town <- combined_table_relevant %>%
group_by(town_name) %>%
summarize(n = n(),
flood_avg = mean(flood_percent),
storm_avg = mean(storm_percent),
heat_avg = mean(heat_percent),
air_pollution_avg = mean(air_pollution_percent),
indoor_air_avg = mean(indoor_air_quality_percent),
chem_hazard_avg = mean(chemical_hazards_percent),
extreme_precip_avg = mean(extreme_precipitation_percent),
fire_avg = mean(fire_percent)
) %>%
mutate(mod_sum = rowSums(across(flood_avg:fire_avg)))
hazard_by_town
hazard_by_town <- combined_table_relevant %>%
group_by(most_common_town) %>%
summarize(n = n(),
flood_avg = mean(flood_percent),
storm_avg = mean(storm_percent),
heat_avg = mean(heat_percent),
air_pollution_avg = mean(air_pollution_percent),
indoor_air_avg = mean(indoor_air_quality_percent),
chem_hazard_avg = mean(chemical_hazards_percent),
extreme_precip_avg = mean(extreme_precipitation_percent),
fire_avg = mean(fire_percent)
) %>%
mutate(mod_sum = rowSums(across(flood_avg:fire_avg)))
hazard_by_town
hazard_by_town %>%
pivot_longer(cols = flood_avg:fire_avg) %>%
ggplot() +
geom_tile(aes(x = reorder(name, value),
y = town_name, fill = value),
color = 'white') +
scale_fill_binned(type = 'viridis')
hazard_by_town %>%
pivot_longer(cols = flood_avg:fire_avg) %>%
ggplot() +
geom_tile(aes(x = reorder(name, value),
y = most_common_town, fill = value),
color = 'white') +
scale_fill_binned(type = 'viridis')
outreach_by_town <- combined_table_relevant %>%
group_by(most_common_town) %>%
summarize(n = n(),
workshop_avg = mean(workshop_percent),
mapping_avg = mean(mapping_percent),
focus_group_avg = mean(focus_group_percent),
interview_avg = mean(interview_percent),
survey_avg = mean(survey_percent),
community_meeting_avg = mean(community_meeting_percent),
small_group_meeting_avg = mean(small_group_meeting_percent),
information_avg = mean(information_percent)
) %>%
mutate(mod_sum = rowSums(across(workshop_avg:information_avg)))
outreach_by_town <- combined_table_relevant %>%
group_by(most_common_town) %>%
summarize(n = n(),
workshop_avg = mean(workshop_percent),
mapping_avg = mean(mapping_percent),
focus_group_avg = mean(focus_group_percent),
interview_avg = mean(interview_percent),
survey_avg = mean(survey_percent),
community_meeting_avg = mean(community_meeting_percent),
small_group_meeting_avg = mean(small_group_meeting_percent),
information_avg = mean(information_percent)
) %>%
mutate(mod_sum = rowSums(across(workshop_avg:information_avg)))
outreach_by_town <- combined_table_relevant %>%
group_by(most_common_town) %>%
summarize(n = n(),
workshop_avg = mean(workshop_percent),
mapping_avg = mean(mapping_percent),
focus_group_avg = mean(focus_group_percent),
interview_avg = mean(interview_percent),
survey_avg = mean(survey_percent),
community_meeting_avg = mean(community_meeting_percent),
small_group_meeting_avg = mean(small_group_meeting_percent),
information_avg = mean(information_percent)
) %>%
mutate(mod_sum = rowSums(across(workshop_avg:information_avg)))
## LOOK AT REVERE AND LEXINGTON
View(outreach_by_town)
outreach_by_town$mod_sum
outreach_by_town %>%
pivot_longer(cols = workshop_avg:information_avg) %>%
ggplot() +
geom_tile(aes(x = reorder(name, value),
y = most_common_town, fill = value),
color = 'white') +
scale_fill_binned(type = 'viridis')
towns_to_include <- toupper(c("Burlington", "Lexington", "Belmont", "Watertown",
"Arlington", "Winchester", "Woburn", "Reading",
"Stoneham", "Medford", "Somerville", "Cambridge",
"Boston", "Everett", "Malden", "Melrose",
"Wakefield", "Chelsea", "Revere", "Winthrop", "Wilmington"))
towns_to_include <- toupper(c("Burlington", "Lexington", "Belmont", "Watertown",
"Arlington", "Winchester", "Woburn", "Reading",
"Stoneham", "Medford", "Somerville", "Cambridge",
"Boston", "Everett", "Malden", "Melrose",
"Wakefield", "Chelsea", "Revere", "Winthrop", "Wilmington"))
#adjust based on your computer
#(put this in the acresnlp folder - should not be in blackouts)
#make background blue to represent water
ma_outline <- states(cb = T) %>% filter(NAME == "Massachusetts")
ma_counties <- counties(state = "MA", cb = T)
ma_counties_no_suffolk <- ma_counties %>% filter(NAME != "Suffolk")
ma_outline_wgs84 <- st_transform(ma_outline, crs = 4326)
bbox <- st_bbox(hazard_towns)
#adjust based on your computer
#(put this in the acresnlp folder - should not be in blackouts)
ma_towns <- read_sf(paste0(my_dir, "towns_fixed.shp"))
hazard_towns <- ma_towns %>%
filter(TOWN20 %in% towns_to_include)
hazard_towns$centroid <- st_centroid(hazard_towns$geometry)
centroids_coords <- st_coordinates(hazard_towns$centroid)
hazard_towns <- ma_towns %>%
filter(TOWN20 %in% towns_to_include)
#make background blue to represent water
ma_outline <- states(cb = T) %>% filter(NAME == "Massachusetts")
ma_counties <- counties(state = "MA", cb = T)
ma_counties_no_suffolk <- ma_counties %>% filter(NAME != "Suffolk")
ma_outline_wgs84 <- st_transform(ma_outline, crs = 4326)
bbox <- st_bbox(hazard_towns)
bbox_sf <- st_as_sfc(bbox)
ma_outline_bbox <- st_crop(ma_outline_wgs84, bbox_sf)
bbox_coords <- st_bbox(ma_outline_bbox)
ACRES_towns_plot <- ma_towns %>%
filter(TOWN20 %in% towns_to_include)
bbox <- st_bbox(ACRES_towns_plot)
bbox_sf <- st_as_sfc(bbox)
ma_outline_bbox <- st_crop(ma_outline_wgs84, bbox_sf)
bbox_coords <- st_bbox(ma_outline_bbox)
####
ACRES_hazard_towns_plot <- ACRES_towns_plot %>%
left_join(hazard_by_town %>% pivot_longer(cols = flood_avg:fire_avg),
by = join_by(TOWN20 == most_common_town))
library(ggpubr)
library(lemon)
hazard_name_map = c(
"air_pollution_avg" = 'Air Pollution',
'chem_hazard_avg' = 'Chemical Hazards',
'extreme_precip_avg' = 'Extreme Precip.',
'fire_avg' = 'Fire',
'flood_avg' = 'Flood',
'heat_avg' = 'Heat',
'indoor_air_avg' = 'Indoor Air',
'storm_avg' = 'Storm'
)
ACRES_hazard_towns_plot$haz_name_plot = hazard_name_map[ACRES_hazard_towns_plot$name]
ggplot(ACRES_hazard_towns_plot %>%
filter(!is.na(value))) + theme_classic2() +
geom_sf(data = ma_counties_no_suffolk,
color = "black", linetype = '11',
fill = "grey") +
geom_sf(aes(fill = value)) +
coord_sf(xlim = c(bbox_coords$xmin - 0.01, bbox_coords$xmax + 0.01),
ylim = c(bbox_coords$ymin - 0.01, bbox_coords$ymax + 0.01),
expand = FALSE) +  # Set plot bounds
scale_fill_binned(type = 'viridis',
name = 'Average per-document\nproportion of\nhazard words\nreferencing hazard X\n') +
facet_rep_wrap(~haz_name_plot, nrow = 2, repeat.tick.labels = 'x') +
xlab(NULL) + ylab(NULL) +
theme(strip.background = element_blank(),
strip.text = element_text(size = 12),
panel.background = element_rect(color = 'black'),
axis.text = element_blank(),
axis.ticks = element_blank())
ggplot(ACRES_hazard_towns_plot %>%
filter(!is.na(value))) + theme_classic2() +
geom_sf(data = ma_counties_no_suffolk,
color = "black", linetype = '11',
fill = "grey") +
geom_sf(aes(fill = value)) +
coord_sf(xlim = c(bbox_coords$xmin - 0.01, bbox_coords$xmax + 0.01),
ylim = c(bbox_coords$ymin - 0.01, bbox_coords$ymax + 0.01),
expand = FALSE) +  # Set plot bounds
scale_fill_binned(type = 'viridis',
name = 'Average per-document\nproportion of\nhazard words\nreferencing hazard X\n') +
#facet_rep_wrap(~haz_name_plot, nrow = 2, repeat.tick.labels = 'x') +
xlab(NULL) + ylab(NULL) +
theme(strip.background = element_blank(),
strip.text = element_text(size = 12),
panel.background = element_rect(color = 'black'),
axis.text = element_blank(),
axis.ticks = element_blank())
####
ACRES_hazard_towns_plot <- ACRES_towns_plot %>%
left_join(hazard_by_town %>% pivot_longer(cols = flood_avg:fire_avg),
by = join_by(TOWN20 == toupper(most_common_town)))
####
ACRES_hazard_towns_plot <- ACRES_towns_plot %>%
left_join(hazard_by_town %>% pivot_longer(cols = flood_avg:fire_avg) %>%
mutate(most_common_town == toupper(most_common_town)),
by = join_by(TOWN20 == most_common_town))
library(ggpubr)
library(lemon)
hazard_name_map = c(
"air_pollution_avg" = 'Air Pollution',
'chem_hazard_avg' = 'Chemical Hazards',
'extreme_precip_avg' = 'Extreme Precip.',
'fire_avg' = 'Fire',
'flood_avg' = 'Flood',
'heat_avg' = 'Heat',
'indoor_air_avg' = 'Indoor Air',
'storm_avg' = 'Storm'
)
ACRES_hazard_towns_plot$haz_name_plot = hazard_name_map[ACRES_hazard_towns_plot$name]
ggplot(ACRES_hazard_towns_plot %>%
filter(!is.na(value))) + theme_classic2() +
geom_sf(data = ma_counties_no_suffolk,
color = "black", linetype = '11',
fill = "grey") +
geom_sf(aes(fill = value)) +
coord_sf(xlim = c(bbox_coords$xmin - 0.01, bbox_coords$xmax + 0.01),
ylim = c(bbox_coords$ymin - 0.01, bbox_coords$ymax + 0.01),
expand = FALSE) +  # Set plot bounds
scale_fill_binned(type = 'viridis',
name = 'Average per-document\nproportion of\nhazard words\nreferencing hazard X\n') +
facet_rep_wrap(~haz_name_plot, nrow = 2, repeat.tick.labels = 'x') +
xlab(NULL) + ylab(NULL) +
theme(strip.background = element_blank(),
strip.text = element_text(size = 12),
panel.background = element_rect(color = 'black'),
axis.text = element_blank(),
axis.ticks = element_blank())
ACRES_hazard_towns_plot
ACRES_hazard_towns_plot$value
mutate(most_common_town == toupper(most_common_town)
)
hazard_by_town %>% pivot_longer(cols = flood_avg:fire_avg) %>%
mutate(most_common_town == toupper(most_common_town))
####
ACRES_hazard_towns_plot <- ACRES_towns_plot %>%
left_join(hazard_by_town %>% pivot_longer(cols = flood_avg:fire_avg) %>%
mutate(most_common_town = toupper(most_common_town)),
by = join_by(TOWN20 == most_common_town))
hazard_by_town %>% pivot_longer(cols = flood_avg:fire_avg) %>%
mutate(most_common_town = toupper(most_common_town))
library(ggpubr)
library(lemon)
hazard_name_map = c(
"air_pollution_avg" = 'Air Pollution',
'chem_hazard_avg' = 'Chemical Hazards',
'extreme_precip_avg' = 'Extreme Precip.',
'fire_avg' = 'Fire',
'flood_avg' = 'Flood',
'heat_avg' = 'Heat',
'indoor_air_avg' = 'Indoor Air',
'storm_avg' = 'Storm'
)
ACRES_hazard_towns_plot$haz_name_plot = hazard_name_map[ACRES_hazard_towns_plot$name]
ACRES_hazard_towns_plot$value
ggplot(ACRES_hazard_towns_plot %>%
filter(!is.na(value))) + theme_classic2() +
geom_sf(data = ma_counties_no_suffolk,
color = "black", linetype = '11',
fill = "grey") +
geom_sf(aes(fill = value)) +
coord_sf(xlim = c(bbox_coords$xmin - 0.01, bbox_coords$xmax + 0.01),
ylim = c(bbox_coords$ymin - 0.01, bbox_coords$ymax + 0.01),
expand = FALSE) +  # Set plot bounds
scale_fill_binned(type = 'viridis',
name = 'Average per-document\nproportion of\nhazard words\nreferencing hazard X\n') +
facet_rep_wrap(~haz_name_plot, nrow = 2, repeat.tick.labels = 'x') +
xlab(NULL) + ylab(NULL) +
theme(strip.background = element_blank(),
strip.text = element_text(size = 12),
panel.background = element_rect(color = 'black'),
axis.text = element_blank(),
axis.ticks = element_blank())

select(is_ACRES_town))
table(combined_table %>%
filter(duplicated == F, is_MASS == T, is_ACRES_town == T) %>%
select(has_climate))
table(combined_table %>%
filter(duplicated == F, is_MASS == T, is_ACRES_town == T,
has_climate == 1) %>%
select(has_community))
table(combined_table %>%
filter(duplicated == F, is_MASS == T, is_ACRES_town == T,
has_climate == 1, has_community == 1) %>%
select(Manual.Check))
combined_table <- combined_table %>%
mutate(pass_checks2 = (
Manual.Check %in% c('INCLUDE', 'INCLDE') &
duplicated == F &
is_ACRES_town == T &
is_MASS == T &
has_climate == 1 &
has_community == 1
))
pass_checks <- combined_table %>%
filter(pass_checks2) %>%
group_by(most_common_town) %>% tally()
sum(pass_checks$n)
write_tsv(pass_checks, 'pass_checks.tsv')
write_tsv(combined_table, 'combined_table_v5_final.tsv')
### make flowchart
table(combined_table$duplicated)
table(combined_table %>% filter(duplicated == F) %>% select(is_MASS))
table(combined_table %>%
filter(duplicated == F, is_MASS == T) %>%
select(is_ACRES_town))
table(combined_table %>%
filter(duplicated == F, is_MASS == T, is_ACRES_town == T) %>%
select(has_climate))
table(combined_table %>%
filter(duplicated == F, is_MASS == T, is_ACRES_town == T,
has_climate == 1) %>%
select(has_community))
table(combined_table %>%
filter(duplicated == F, is_MASS == T, is_ACRES_town == T,
has_climate == 1, has_community == 1) %>%
select(Manual.Check))
# get tidycensus data for towns
# TABLE 1!!!!!!!!
# Last modified:
# * 8/9=14/2024 MK
# * 8.19.2024 - CWM
# * 8.26.2024 AMJ
# -----------------------------------------------------------------------------
# load in libraries
library(tidyverse)
library(sf)
library(ggplot2)
library(readxl)
library(dplyr)
library(ggrepel)
library(tigris)
library(tidycensus)
library(gt)
library(stringr)
getwd()
setwd("../")
# setwd("C:/Users/mkhemani/OneDrive - Boston University/02_Blackouts")
# setwd("/Users/alliej/Library/CloudStorage/OneDrive-BostonUniversity/02_Blackouts/")
# -----------------------------------------------------------------------------
# bring in acs data
census_api_key("cf7ba23c01a84fe015a7669aa755f04bd2fcb4e2",
overwrite = TRUE, install = TRUE)
# towns
towns_MA <- county_subdivisions(state = "MA", year = 2020)
variables <- c(
"B01003_001",      # Total population
"B19013_001",      # Median household income
"B02001_002",      # White alone
"B02001_003",      # Black or African American alone
"B02001_004",      # American Indian and Alaska Native alone
"B02001_005",      # Asian alone
"B02001_006",      # Native Hawaiian and Other Pacific Islander alone
"B02001_007",      # Some other race alone
"B02001_008"       # Two or more races
)
# Fetch ACS data
town_pop_data <- get_acs(
geography = "county subdivision",
state = "MA",
variables = variables,
year = 2020,
survey = "acs5"
)
town_pop_data <- town_pop_data %>%
rename(town = NAME, population = estimate) %>%
select(GEOID, town, population)
town_pop_data
# Fetch ACS data
town_pop_data <- get_acs(
geography = "county subdivision",
state = "MA",
variables = variables,
year = 2020,
survey = "acs5"
)
head(town_pop_data)
dim(town_pop_data)
town_pop_data <- town_pop_data %>% select(-moe) %>%
pivot_wider(id_cols = c(GEOID, NAME), names_from = variable,
values_from = estimate)
head(town_pop_data)
dim(town_pop_data)
mystic_towns_list = c("Burlington", "Lexington", "Belmont", "Watertown",
"Arlington", "Winchester", "Woburn", "Reading",
"Stoneham", "Medford", "Somerville", "Cambridge",
"Boston", "Charlestown", "Everett", "Malden", "Melrose",
"Wakefield", "Chelsea", "Revere", "Winthrop", "Wilmington")
town_pop_data <- town_pop_data %>% arrange(NAME)
town_pop_data
town_pop_data$NAME
town_pop_data <- town_pop_data[, (length(variables)+1):nrow(town_pop_data)] %>% select(-moe) %>%
pivot_wider(id_cols = c(GEOID, NAME), names_from = variable,
values_from = estimate)
variables <- c(
"B01003_001",      # Total population
"B19013_001",      # Median household income
"B02001_002",      # White alone
"B02001_003",      # Black or African American alone
"B02001_004",      # American Indian and Alaska Native alone
"B02001_005",      # Asian alone
"B02001_006",      # Native Hawaiian and Other Pacific Islander alone
"B02001_007",      # Some other race alone
"B02001_008"       # Two or more races
)
# Fetch ACS data
town_pop_data <- get_acs(
geography = "county subdivision",
state = "MA",
variables = variables,
year = 2020,
survey = "acs5"
)
town_pop_data <- town_pop_data[, (length(variables)+1):nrow(town_pop_data)] %>% select(-moe) %>%
pivot_wider(id_cols = c(GEOID, NAME), names_from = variable,
values_from = estimate)
town_pop_data <- town_pop_data[(length(variables)+1):nrow(town_pop_data), ] %>% select(-moe) %>%
pivot_wider(id_cols = c(GEOID, NAME), names_from = variable,
values_from = estimate)
dim(town_pop_data)
town_pop_data <- town_pop_data %>% arrange(NAME)
town_pop_data$NAME
grepl(mystic_towns_list, town_pop_data$NAME)
sapply(mystic_towns_list, function(ti) which(grepl(ti, town_pop_data$NAME)))
# Fetch ACS data
town_pop_data <- get_acs(
geography = "places",
state = "MA",
variables = variables,
year = 2020,
survey = "acs5"
)
# Fetch ACS data
town_pop_data <- get_acs(
geography = "place",
state = "MA",
variables = variables,
year = 2020,
survey = "acs5"
)
town_pop_data <- town_pop_data[(length(variables)+1):nrow(town_pop_data), ] %>% select(-moe) %>%
pivot_wider(id_cols = c(GEOID, NAME), names_from = variable,
values_from = estimate)
dim(town_pop_data)
town_pop_data <- town_pop_data %>% arrange(NAME)
town_pop_data$NAME
combined_table
library(readr)
library(tidyverse)
library(ggforce)
library(janitor)
library(sf)
library(gtable)
library(grid)
library(gridExtra)
library(tigris)
library(leaflet)
### NOTES
# * STONEHAM HAS NO CLIMATE REPORTS
# * NOT A LOT OF ADJACENCY IN HAZARDS
#
# *
# * allison: for both hazards and outreach, for some towns the totals are < 100%
# * chad: expanding heat search terms and seeing if that changes things, manual search
# Needs:
# * Map
# * table of the heatmap with %s and n
# * REVERE AND LEXINGTON DON'T HAVE 100% in relevancy table
# * WHY ISNT HEAT MORE ** SEARCH TERMS
#
# * WHAT ABOUT THE COMMUNITY CONCERNS
# ----------------------------------------------------------------------------
#### create dataframe of hazard counts and proportions by town ####
#adjust based on your computer
#my_dir <- "/Users/alliej/Library/CloudStorage/OneDrive-BostonUniversity/ACRES NLP/acresNLP/"
my_dir <- "/Users/cwm/Documents/GitHub/acresNLP/"
# my_dir <- "C:/Users/ncesare/Downloads/"
create_df <- function(filename){
data <- read_delim(filename)
return(data)
}
#combined table missing all arlington/belmont and some chelsea/everett
combined_table <- create_df(paste0(my_dir, "combined_output_v5.tsv"))
colnames(combined_table)
combined_table <- combined_table %>% clean_names()
combined_table$town_name <- gsub("url\\d+|\\d+|\\.json", "",
combined_table$file_name)
combined_table$town_name <- toupper(combined_table$town_name)
#View(combined_table)
mystic_towns_list = c("Burlington", "Lexington", "Belmont", "Watertown",
"Arlington", "Winchester", "Woburn", "Reading",
"Stoneham", "Medford", "Somerville", "Cambridge",
"Boston", "Charlestown", "Everett", "Malden", "Melrose",
"Wakefield", "Chelsea", "Revere", "Winthrop", "Wilmington")
##
combined_table <- combined_table %>%
mutate(is_ACRES_town = (most_common_town %in% tolower(mystic_towns_list)),
is_MASS = (most_common_state == 'massachusetts'))
# duplicated
combined_table$duplicated = duplicated(combined_table$first100words)
# write_tsv(combined_table[, c('file_name', 'duplicated')] %>%
#             arrange(file_name), 'duplicated.tsv')
combined_table <- combined_table %>%
mutate(pass_checks2 = (
duplicated == F &
is_ACRES_town == T &
is_MASS == T &
has_climate == 1 &
has_community == 1
))
write_tsv(combined_table, 'combined_table_v5.tsv')
combined_table
table(combined_table$most_common_town, combined_table$pass_checks2)
table(combined_table$pass_checks2)
mancx <- read.csv(paste0(my_dir, "manual_checks_2.csv"), header = T,
sep = "|")[,c('Manual.Check', "file_name")]
head(mancx)
combined_table <- combined_table %>% left_join(mancx)
dim(combined_table)
data.frame(head(combined_table))
# ----------------------------------------------------------------------------
# ma.url omitted
combined_table <- combined_table %>%
mutate(pass_checks2 = (
Manual.Check %in% c('INCLUDE', 'INCLDE') &
duplicated == F &
is_ACRES_town == T &
is_MASS == T &
has_climate == 1 &
has_community == 1
))
pass_checks <- combined_table %>%
filter(pass_checks2) %>%
group_by(most_common_town) %>% tally()
sum(pass_checks$n)
write_tsv(pass_checks, 'pass_checks.tsv')
# num_irrelevant <- combined_table %>%
#   group_by(town_name) %>%
#   summarize(
#     total_pdfs = n(),
#     total_relevant = sum(relevant),
#     percent_relevant = total_relevant / n(),
#     total_towns_match = sum(towns_match),
#     percent_match = total_towns_match / n(),
#     relevant_and_match = sum(relevant & towns_match)
#     )
#
# View(num_irrelevant)
#only filter for relevant and matching
write_tsv(combined_table, 'combined_table_v5_final.tsv')
combined_table_v5_final
combined_table
combined_table$most_common_town
which(combined_table$most_common_town == 'charlestown')
grepl(mystic_towns_list, town_pop_data$NAME)
sapply(mystic_towns_list, function(ti) which(grepl(ti, town_pop_data$NAME)))
xi <- do.call(c, x)
x <- sapply(mystic_towns_list, function(ti) which(grepl(ti, town_pop_data$NAME)))
xi <- do.call(c, x)
xi
town_pop_data[xi, ]
variables <- c(
"B01003_001",      # Total population
"B19013_001",      # Median household income
)
variables <- c(
"B01003_001",      # Total population
"B19013_001"      # Median household income
)
towns_to_include <- toupper(c("Burlington", "Lexington", "Belmont", "Watertown",
"Arlington", "Winchester", "Woburn", "Reading",
"Stoneham", "Medford", "Somerville", "Cambridge",
"Boston", "Everett", "Malden", "Melrose",
"Wakefield", "Chelsea", "Revere", "Winthrop", "Wilmington"))
#adjust based on your computer
#(put this in the acresnlp folder - should not be in blackouts)
ma_towns <- read_sf(paste0(my_dir, "towns_fixed.shp"))
ACRES_towns_plot <- ma_towns %>%
filter(TOWN20 %in% towns_to_include)
#make background blue to represent water
ma_outline <- states(cb = T) %>% filter(NAME == "Massachusetts")
ma_counties <- counties(state = "MA", cb = T)
ma_counties_no_suffolk <- ma_counties %>% filter(NAME != "Suffolk")
ma_outline_wgs84 <- st_transform(ma_outline, crs = 4326)
bbox <- st_bbox(ACRES_towns_plot)
bbox_sf <- st_as_sfc(bbox)
ma_outline_bbox <- st_crop(ma_outline_wgs84, bbox_sf)
bbox_coords <- st_bbox(ma_outline_bbox)
####
ACRES_hazard_town_plot <- ACRES_towns_plot %>%
left_join(hazard_by_town %>% pivot_longer(cols = flood_avg:fire_avg) %>%
mutate(most_common_town = toupper(most_common_town)),
by = join_by(TOWN20 == most_common_town))
hazard_by_town %>% pivot_longer(cols = flood_avg:fire_avg) %>%
mutate(most_common_town = toupper(most_common_town))
library(ggpubr)
library(lemon)
# ----------------------------------------------------------------------------
#90% or over for all towns
combined_table_relevant <- combined_table %>%
filter(pass_checks2)
dim(combined_table_relevant)
dim(combined_table)
dim(combined_table_relevant)
mystic_towns_list <- tolower(c("Burlington", "Lexington", "Belmont", "Watertown",
"Arlington", "Winchester", "Woburn", "Reading",
"Stoneham", "Medford", "Somerville", "Cambridge",
"Boston", "Charlestown", "Everett", "Malden", "Melrose",
"Wakefield", "Chelsea", "Revere", "Winthrop", "Wilmington"))
hazard_by_town <- combined_table_relevant %>%
group_by(most_common_town) %>%
summarize(n = n(),
flood_avg = mean(flood_percent),
storm_avg = mean(storm_percent),
heat_avg = mean(heat_percent),
air_pollution_avg = mean(air_pollution_percent),
indoor_air_avg = mean(indoor_air_quality_percent),
chem_hazard_avg = mean(chemical_hazards_percent),
extreme_precip_avg = mean(extreme_precipitation_percent),
fire_avg = mean(fire_percent)
) %>%
mutate(mod_sum = rowSums(across(flood_avg:fire_avg)))
mystic_towns_list_sub <- setdiff(mystic_towns_list,  unique(hazard_by_town$most_common_town))
hazard_by_town_blank <- data.frame(most_common_town = mystic_towns_list_sub,
n = rep(0, length(mystic_towns_list_sub)),
flood_avg = rep(NA, length(mystic_towns_list_sub)),
storm_avg = rep(NA, length(mystic_towns_list_sub)),
heat_avg = rep(NA, length(mystic_towns_list_sub)),
air_pollution_avg = rep(NA, length(mystic_towns_list_sub)),
indoor_air_avg = rep(NA, length(mystic_towns_list_sub)),
chem_hazard_avg = rep(NA, length(mystic_towns_list_sub)),
extreme_precip_avg = rep(NA, length(mystic_towns_list_sub)),
fire_avg = rep(NA, length(mystic_towns_list_sub)),
mod_sum = rep(0, length(mystic_towns_list_sub)))
hazard_by_town$mod_sum
hazard_by_town <- rbind(hazard_by_town, hazard_by_town_blank)
hazard_name_map = c(
"air_pollution_avg" = 'Air Pollution',
'chem_hazard_avg' = 'Chemical Hazards',
'extreme_precip_avg' = 'Extreme Precipitation',
'fire_avg' = 'Fire',
'flood_avg' = 'Flood',
'heat_avg' = 'Heat',
'indoor_air_avg' = 'Indoor Air',
'storm_avg' = 'Storm'
)
capitalizeFirstLetter <- function(textVector) {
# Helper function to capitalize the first letter of a single string
singleCapitalize <- function(text) {
# Capitalize the first letter and leave the rest unchanged
paste0(toupper(substr(text, 1, 1)), substr(text, 2, nchar(text)))
}
# Apply the singleCapitalize function to each string in the vector
result <- sapply(textVector, singleCapitalize)
return(result)
}
# Example usage:
capitalizeFirstLetter(c("convert_text to camel_case", "another_example_here", "hello world"))
hazard_by_town
p1 <- hazard_by_town %>%
pivot_longer(cols = flood_avg:fire_avg) %>%
mutate(value = ifelse(value == 0, NA, value),
name_nice = hazard_name_map[name],
town_name_nice = paste0(capitalizeFirstLetter(most_common_town), " (", n, ")")) %>%
ggplot() +
geom_tile(aes(y = reorder(name_nice, value, na.rm = T),
x = town_name_nice,
fill = value),
color = 'white') +
scale_fill_binned(type = 'viridis',
name = 'Average proportion\nof per-document\nreferences',
limits = c(0, 100),
breaks = c(seq(20, 80, by = 20))) +
ylab('Hazard') + xlab('Town') +
scale_x_discrete(position = 'top') +
theme(axis.text.x = element_text(angle = 35, hjust = 0, size = 11),
axis.text.y = element_text(size = 14),
axis.title = element_text(size = 14))
p1
ggsave(filename = 'hazplot_v5.png',
width = 13.375000 * 0.8,
height = 4.361111 * 0.8,
dpi = 600)
variables <- c(
"B01003_001",      # Total population
"B19013_001"      # Median household income
)
# Fetch ACS data
town_pop_data <- get_acs(
geography = "place",
state = "MA",
variables = variables,
year = 2020,
survey = "acs5"
)
town_pop_data <- town_pop_data[(length(variables)+1):nrow(town_pop_data), ] %>% select(-moe) %>%
pivot_wider(id_cols = c(GEOID, NAME), names_from = variable,
values_from = estimate)
dim(town_pop_data)
town_pop_data <- town_pop_data %>% arrange(NAME)
town_pop_data$NAME
town_pop_data <- town_pop_data %>% select(-moe) %>%
pivot_wider(id_cols = c(GEOID, NAME), names_from = variable,
values_from = estimate)
# Fetch ACS data
town_pop_data <- get_acs(
geography = "place",
state = "MA",
variables = variables,
year = 2020,
survey = "acs5"
)
town_pop_data <- town_pop_data %>% select(-moe) %>%
pivot_wider(id_cols = c(GEOID, NAME), names_from = variable,
values_from = estimate)
dim(town_pop_data)
town_pop_data <- town_pop_data %>% arrange(NAME)
town_pop_data$NAME
# Fetch ACS data
town_pop_data <- get_acs(
geography = "county subdivision",
state = "MA",
variables = variables,
year = 2020,
survey = "acs5"
)
town_pop_data <- town_pop_data %>% select(-moe) %>%
pivot_wider(id_cols = c(GEOID, NAME), names_from = variable,
values_from = estimate)
dim(town_pop_data)
town_pop_data <- town_pop_data %>% arrange(NAME)
town_pop_data$NAME
mystic_towns_list = c("Burlington", "Lexington", "Belmont", "Watertown",
"Arlington", "Winchester", "Woburn", "Reading",
"Stoneham", "Medford", "Somerville", "Cambridge",
"Boston", "Charlestown", "Everett", "Malden", "Melrose",
"Wakefield", "Chelsea", "Revere", "Winthrop", "Wilmington")
x <- sapply(mystic_towns_list, function(ti) which(grepl(ti, town_pop_data$NAME)))
xi <- do.call(c, x)
town_pop_data[xi, ]
ACRES <- town_pop_data[xi, ]
ACRES$town_name <- xi
ACRES[, c('town_name', 'B01003_001', 'B19013_001')]
ACRES$town_name <- mystic_towns_list
ACRES[, c('town_name', 'B01003_001', 'B19013_001')]
write.csv(ACRES[, c('town_name', 'B01003_001', 'B19013_001')],'ACRES.csv')
mystic_towns_list = c("Burlington", "Lexington", "Belmont", "Watertown",
"Arlington", "Winchester", "Woburn", "Reading",
"Stoneham", "Medford", "Somerville", "Cambridge",
"Boston", "Everett", "Malden", "Melrose",
"Wakefield", "Chelsea", "Revere", "Winthrop", "Wilmington")
x <- sapply(mystic_towns_list, function(ti) which(grepl(ti, town_pop_data$NAME)))
xi <- do.call(c, x)
ACRES <- town_pop_data[xi, ]
ACRES$town_name <- mystic_towns_list
# Fetch ACS data
town_pop_data <- get_acs(
geography = "county subdivision",
state = "MA",
variables = variables,
year = 2020,
survey = "acs5"
)
town_pop_data <- town_pop_data %>% select(-moe) %>%
pivot_wider(id_cols = c(GEOID, NAME), names_from = variable,
values_from = estimate)
dim(town_pop_data)
town_pop_data <- town_pop_data %>% arrange(NAME)
town_pop_data$NAME
mystic_towns_list = c("Burlington", "Lexington", "Belmont", "Watertown",
"Arlington", "Winchester", "Woburn", "Reading",
"Stoneham", "Medford", "Somerville", "Cambridge",
"Boston", "Everett", "Malden", "Melrose",
"Wakefield", "Chelsea", "Revere", "Winthrop", "Wilmington")
x <- sapply(mystic_towns_list, function(ti) which(grepl(ti, town_pop_data$NAME)))
x
xi <- do.call(c, x)
ACRES <- town_pop_data[xi, ]
ACRES$town_name <- mystic_towns_list
x$Reading
x$Reading <- 252
xi <- do.call(c, x)
ACRES <- town_pop_data[xi, ]
ACRES$town_name <- mystic_towns_list
write.csv(ACRES[, c('town_name', 'B01003_001', 'B19013_001')],'ACRES.csv')
